{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f72a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sqlite3\n",
    "from transformers import AutoTokenizer\n",
    "access_token = \"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\"\n",
    "\n",
    "def semantic_search(query, database='raw/tokenized_data_llama2.db'):\n",
    "    conn = sqlite3.connect(database)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve all chunk texts from the database\n",
    "    cursor.execute(\"SELECT chunk_text FROM tokenized_chunks\")\n",
    "    rows = cursor.fetchall()\n",
    "    chunk_texts = [row[0] for row in rows]\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token = access_token)\n",
    "\n",
    "\n",
    "    # Vectorize query and chunk texts using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([query] + chunk_texts)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    sorted_chunk_indices = cosine_similarities.argsort()[::-1]\n",
    "    top_chunk_indices = sorted_chunk_indices[:2]\n",
    "\n",
    "    top_matching_chunks = []\n",
    "    for i in top_chunk_indices:\n",
    "        # Tokenize the chunk text\n",
    "        tokens = tokenizer.tokenize(chunk_texts[i])\n",
    "        # Count the number of tokens\n",
    "        num_tokens = len(tokens)\n",
    "        # Store chunk text along with cosine similarity and number of tokens\n",
    "        top_matching_chunks.append((cosine_similarities[i], chunk_texts[i], num_tokens))\n",
    "\n",
    "    conn.close()\n",
    "    return top_matching_chunks[0]\n",
    "\n",
    "# query = \"Elesh Norn, Grand Cenobite\"\n",
    "# matching_chunks = semantic_search(query)\n",
    "\n",
    "# for i, (cosine_similarity_score, chunk, num_tokens) in enumerate(matching_chunks):\n",
    "#     # Remove <s> tags from the chunk text\n",
    "#     clean_chunk = chunk.replace('<s>', '')\n",
    "#     print(f\"Matching Chunk {i + 1}: (Cosine Similarity: {cosine_similarity_score}, Tokens: {num_tokens})\")\n",
    "#     print(clean_chunk)\n",
    "#     print(\"-o\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa864a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RAG_eval_data_raw = \"RAG_MTG_Test.csv\"\n",
    "RAG_eval_data = pd.read_csv(RAG_eval_data_raw)\n",
    "CARD_INFO_DF = pd.read_csv(\"raw/filtered_oracle_database.csv\")\n",
    "CARD_EVAL_DF = pd.read_csv(\"RAG_MTG_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4715d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMATTED_DATA = []\n",
    "\n",
    "for name in CARD_EVAL_DF[\"Card Name\"].tolist():\n",
    "    card_info = CARD_INFO_DF[CARD_INFO_DF[\"name\"] == name]\n",
    "\n",
    "    formatted_info = \"\"\n",
    "    for index, row in card_info.iterrows():\n",
    "        formatted_row = \"\"\n",
    "        for column_name, value in row.items():\n",
    "            formatted_row += f\"{column_name}: {value}\\n\"\n",
    "        formatted_info += formatted_row.strip() + \"\\n\"\n",
    "        \n",
    "        FORMATTED_DATA.append(formatted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41091e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c6db23f7fc40288cd130e75d6050a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token = access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token = access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd35b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_card_model_inference(model, tokenizer, card_name, card_information):\n",
    "    \n",
    "    raw_text_prompt = f\"I want you to tell me the following information about {card_name} in this exact same format:\\nname:\\nmana_cost:\\ncmc:\\ntype_line:\\noracle_text:\\npower:\\ntoughness:\\ncolors:\\ncolor_identity:\\nkeywords: \\nDo not provide any other context for this, all I want is to know the listed parameters for this card.\"\n",
    "    \n",
    "    raw_chunk_data = semantic_search(card_name)[1].replace('<s>', '')\n",
    "    \n",
    "    RAG_text_prompt = raw_chunk_data + \"\\n\" + raw_text_prompt\n",
    "    input_ids = tokenizer.encode(raw_text_prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, min_new_tokens = 70, max_length=2048, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode and display the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6efcb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_card_name = CARD_EVAL_DF[\"Card Name\"].iloc[0]\n",
    "test_card_info = FORMATTED_DATA[0]\n",
    "generated_card_info = run_card_model_inference(model, tokenizer, test_card_name, test_card_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7a04ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want you to tell me the following information about Goldnight Redeemer in this exact same format:\n",
      "name:\n",
      "mana_cost:\n",
      "cmc:\n",
      "type_line:\n",
      "oracle_text:\n",
      "power:\n",
      "toughness:\n",
      "colors:\n",
      "color_identity:\n",
      "keywords:\n",
      "rarity:\n",
      "\n",
      "name: Goldnight Redeemer\n",
      "\n",
      "mana_cost: 4GG\n",
      "\n",
      "cmc: 4\n",
      "\n",
      "type_line: Creature - Human Cleric\n",
      "\n",
      "oracle_text: Whenever Goldnight Redeemer deals combat damage to a player, you may return that player's card to their hand. If you do, create a 2/2 white Human Cleric creature token.\n",
      "\n",
      "power: 3\n",
      "\n",
      "toughness: 3\n",
      "\n",
      "colors: White\n",
      "\n",
      "color_identity: White\n",
      "\n",
      "keywords: Return to Hand, Creature\n",
      "\n",
      "rarity: Rare\n",
      "\n",
      "I hope that helps! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "print(generated_card_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"name: Goldnight Redeemer\n",
    "mana_cost: 3UU\n",
    "cmc: 3\n",
    "type_line: Creature - Angel\n",
    "oracle_text: Whenever Goldnight Redeemer deals combat damage to a player, that player discards a card.\n",
    "power: 4\n",
    "toughness: 4\n",
    "colors: U, U/B\n",
    "color_identity: Blue\n",
    "keywords: Flying, Lifelink\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
